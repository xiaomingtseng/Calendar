import React, { useState, useRef, useCallback } from 'react';

interface VoiceInputProps {
  onResult: (text: string) => void;
  onError?: (error: string) => void;
  placeholder?: string;
  className?: string;
}

export const VoiceInput: React.FC<VoiceInputProps> = ({
  onResult,
  onError,
  placeholder = "é»æ“Šéº¥å…‹é¢¨é–‹å§‹èªéŸ³è¼¸å…¥...",
  className = ""
}) => {
  const [isListening, setIsListening] = useState(false);
  const [isSupported, setIsSupported] = useState(true);
  const [lastResult, setLastResult] = useState<string>('');
  const recognitionRef = useRef<any>(null);

  // æª¢æŸ¥ç€è¦½å™¨æ”¯æ´
  React.useEffect(() => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      setIsSupported(false);
      onError?.('æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è­˜åˆ¥åŠŸèƒ½');
    }
  }, [onError]);

  const startListening = useCallback(() => {
    if (!isSupported) return;

    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'zh-TW'; // ç¹é«”ä¸­æ–‡
      
      recognition.onstart = () => {
        console.log('èªéŸ³è­˜åˆ¥é–‹å§‹');
        setIsListening(true);
        setLastResult('');
      };
      
      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        const confidence = event.results[0][0].confidence;
        console.log('èªéŸ³è­˜åˆ¥çµæœ:', transcript, 'ä¿¡å¿ƒåº¦:', confidence);
        
        setLastResult(transcript);
        onResult(transcript);
        setIsListening(false);
      };
      
      recognition.onerror = (event) => {
        console.error('èªéŸ³è­˜åˆ¥éŒ¯èª¤:', event.error);
        const errorMessage = getErrorMessage(event.error);
        onError?.(errorMessage);
        setIsListening(false);
      };
      
      recognition.onend = () => {
        console.log('èªéŸ³è­˜åˆ¥çµæŸ');
        setIsListening(false);
      };

      recognitionRef.current = recognition;
      recognition.start();
    } catch (error) {
      console.error('å•Ÿå‹•èªéŸ³è­˜åˆ¥å¤±æ•—:', error);
      onError?.('å•Ÿå‹•èªéŸ³è­˜åˆ¥å¤±æ•—');
      setIsListening(false);
    }
  }, [isSupported, onResult, onError]);

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      setIsListening(false);
    }
  }, []);

  const getErrorMessage = (error: string): string => {
    switch (error) {
      case 'no-speech':
        return 'æ²’æœ‰åµæ¸¬åˆ°èªéŸ³ï¼Œè«‹å†è©¦ä¸€æ¬¡';
      case 'audio-capture':
        return 'ç„¡æ³•å­˜å–éº¥å…‹é¢¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™è¨­å®š';
      case 'not-allowed':
        return 'éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•ï¼Œè«‹å…è¨±ä½¿ç”¨éº¥å…‹é¢¨';
      case 'network':
        return 'ç¶²è·¯é€£ç·šå•é¡Œï¼Œè«‹æª¢æŸ¥ç¶²è·¯';
      case 'service-not-allowed':
        return 'èªéŸ³æœå‹™ä¸å¯ç”¨';
      default:
        return `èªéŸ³è­˜åˆ¥ç™¼ç”ŸéŒ¯èª¤: ${error}`;
    }
  };

  if (!isSupported) {
    return (
      <div style={{ 
        padding: '0.5rem', 
        fontSize: '0.875rem', 
        color: '#6b7280',
        textAlign: 'center'
      }}>
        æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è¼¸å…¥åŠŸèƒ½
      </div>
    );
  }

  return (
    <div style={{ display: 'flex', alignItems: 'center', gap: '0.75rem' }} className={className}>
      <button
        type="button"
        onClick={isListening ? stopListening : startListening}
        disabled={!isSupported}
        style={{
          padding: '0.625rem',
          borderRadius: '50%',
          border: 'none',
          cursor: isSupported ? 'pointer' : 'not-allowed',
          transition: 'all 0.2s ease',
          backgroundColor: isListening ? '#ef4444' : '#3b82f6',
          color: 'white',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          width: '48px',
          height: '48px',
          boxShadow: isListening ? '0 0 20px rgba(239, 68, 68, 0.5)' : '0 2px 8px rgba(59, 130, 246, 0.3)',
          animation: isListening ? 'pulse 1.5s infinite' : 'none'
        }}
        onMouseEnter={(e) => {
          if (!isListening && isSupported) {
            e.currentTarget.style.backgroundColor = '#2563eb';
            e.currentTarget.style.transform = 'scale(1.05)';
          }
        }}
        onMouseLeave={(e) => {
          if (!isListening) {
            e.currentTarget.style.backgroundColor = '#3b82f6';
            e.currentTarget.style.transform = 'scale(1)';
          }
        }}
        title={isListening ? 'é»æ“Šåœæ­¢éŒ„éŸ³' : 'é»æ“Šé–‹å§‹èªéŸ³è¼¸å…¥'}
      >
        {isListening ? (
          // åœæ­¢åœ–ç¤º
          <svg width="20" height="20" fill="currentColor" viewBox="0 0 20 20">
            <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clipRule="evenodd" />
          </svg>
        ) : (
          // éº¥å…‹é¢¨åœ–ç¤º
          <svg width="20" height="20" fill="currentColor" viewBox="0 0 20 20">
            <path fillRule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clipRule="evenodd" />
          </svg>
        )}
      </button>
      
      <div style={{ flex: 1 }}>
        <div style={{
          fontSize: '0.875rem',
          color: isListening ? '#ef4444' : '#6b7280',
          fontWeight: isListening ? 'bold' : 'normal'
        }}>
          {isListening ? 'ğŸ¤ æ­£åœ¨è†è½...' : placeholder}
        </div>
        {lastResult && (
          <div style={{
            fontSize: '0.8rem',
            color: '#9ca3af',
            marginTop: '0.25rem',
            fontStyle: 'italic'
          }}>
            ä¸Šæ¬¡è­˜åˆ¥: {lastResult}
          </div>
        )}
      </div>
    </div>
  );
};
